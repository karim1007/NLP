{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel, AlbertTokenizer, AlbertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import textract\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Fetch the API key\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_CONFIGS = [\n",
    "    {\n",
    "        'name': 'bert-base-uncased',\n",
    "        'tokenizer_class': BertTokenizer,\n",
    "        'model_class': BertModel,\n",
    "        'weight': 0.5  # Configurable weight for each model\n",
    "    },\n",
    "    {\n",
    "        'name': 'roberta-base',\n",
    "        'tokenizer_class': RobertaTokenizer,\n",
    "        'model_class': RobertaModel,\n",
    "        'weight': 0.5\n",
    "    },\n",
    "   \n",
    "]\n",
    "# Initialize models and tokenizers\n",
    "def initialize_models():\n",
    "    models = {}\n",
    "    for config in MODEL_CONFIGS:\n",
    "        name = config['name']\n",
    "        tokenizer = config['tokenizer_class'].from_pretrained(name)\n",
    "        model = config['model_class'].from_pretrained(name)\n",
    "        models[name] = {\n",
    "            'tokenizer': tokenizer,\n",
    "            'model': model\n",
    "        }\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_embeddings(text, model_info):\n",
    "    tokenizer = model_info['tokenizer']\n",
    "    model = model_info['model']\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get the outputs, including attention weights\n",
    "        outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "    # Extract the token embeddings and attention weights\n",
    "    token_embeddings = outputs.last_hidden_state  # Shape: (batch_size, seq_length, hidden_dim)\n",
    "    attention_weights = outputs.attentions[-1]   # Last layer attention, shape: (batch_size, num_heads, seq_length, seq_length)\n",
    "\n",
    "    # Average the attention weights across all heads\n",
    "    avg_attention = attention_weights.mean(dim=1)  # Shape: (batch_size, seq_length, seq_length)\n",
    "\n",
    "    # Weight the token embeddings with the averaged attention\n",
    "    weighted_embeddings = torch.matmul(avg_attention, token_embeddings)  # Shape: (batch_size, seq_length, hidden_dim)\n",
    "\n",
    "    # Aggregate embeddings (e.g., mean pooling over the sequence length dimension)\n",
    "    sentence_embedding = weighted_embeddings.mean(dim=1).squeeze(0).numpy()  # Shape: (hidden_dim,)\n",
    "\n",
    "    return sentence_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to preprocess resume text into different sections\n",
    "def preprocess_resume(text):\n",
    "    try:\n",
    "        # Initialize sections with expanded keywords\n",
    "        sections = {\n",
    "            'work_experience': '', \n",
    "            'education': '', \n",
    "            'skills': '',\n",
    "            'contact_info': '',\n",
    "            'summary': '',\n",
    "            'certifications': '',\n",
    "            'projects': '',\n",
    "            'languages': ''\n",
    "        }\n",
    "\n",
    "        # Expanded keywords for section detection\n",
    "        section_keywords = {\n",
    "            'work_experience': [\n",
    "                'work experience', 'professional experience', 'employment history', \n",
    "                'career', 'professional background', 'work history', 'experience'\n",
    "            ],\n",
    "            'education': [\n",
    "                'education', 'academic background', 'educational qualifications', \n",
    "                'academic history', 'academic details', 'degrees'\n",
    "            ],\n",
    "            'skills': [\n",
    "                'skills', 'technical skills', 'skills summary', 'core competencies', \n",
    "                'professional skills', 'key skills'\n",
    "            ],\n",
    "            'contact_info': [\n",
    "                'contact information', 'contact details', 'personal information', \n",
    "                'contact', 'personal details'\n",
    "            ],\n",
    "            'summary': [\n",
    "                'professional summary', 'profile', 'career objective', \n",
    "                'professional profile', 'career summary'\n",
    "            ],\n",
    "            'certifications': [\n",
    "                'certifications', 'professional certifications', 'certificates', \n",
    "                'professional credentials'\n",
    "            ],\n",
    "            'projects': [\n",
    "                'projects', 'project experience', 'professional projects', \n",
    "                'key projects'\n",
    "            ],\n",
    "            'languages': [\n",
    "                'languages', 'language skills', 'spoken languages', 'language proficiency'\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Load stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        # Convert text to lowercase for case-insensitive matching\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        # Tokenize text and remove stop words\n",
    "        words = word_tokenize(text_lower)\n",
    "        filtered_text = ' '.join(word for word in words if word not in stop_words)\n",
    "        \n",
    "        # Find starting indices for each section\n",
    "        section_indices = {}\n",
    "        for section, keywords in section_keywords.items():\n",
    "            # Find the minimum index of any matching keyword\n",
    "            indices = [filtered_text.find(keyword) for keyword in keywords if keyword in filtered_text]\n",
    "            section_indices[section] = min(indices) if indices else -1\n",
    "\n",
    "        # Sort the indices to help with section extraction\n",
    "        sorted_sections = sorted(\n",
    "            [(section, index) for section, index in section_indices.items() if index != -1], \n",
    "            key=lambda x: x[1]\n",
    "        )\n",
    "\n",
    "        # Extract sections based on their positions\n",
    "        for i, (section, start_index) in enumerate(sorted_sections):\n",
    "            # Determine the end index by looking at the start of the next section\n",
    "            end_index = sorted_sections[i+1][1] if i+1 < len(sorted_sections) else len(filtered_text)\n",
    "\n",
    "            # Extract the section content\n",
    "            sections[section] = filtered_text[start_index:end_index].strip()\n",
    "        print(sections)\n",
    "        \n",
    "        return sections\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing resume text: {e}\")\n",
    "        return {\n",
    "            'work_experience': '', \n",
    "            'education': '', \n",
    "            'skills': '',\n",
    "            'contact_info': '',\n",
    "            'summary': '',\n",
    "            'certifications': '',\n",
    "            'projects': '',\n",
    "            'languages': ''\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import PyPDF2\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "\n",
    "    # Open the uploaded PDF\n",
    "    \n",
    "# Function to extract text from a local file\n",
    "def extract_text_from_file(file_path):\n",
    "    print(file_path)\n",
    "    try:\n",
    "        \n",
    "        with open(file_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            \n",
    "            # Loop through all pages and extract text\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "        \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {file_path}: {e}\")\n",
    "        return \"\"\n",
    "def search_resumes(job_description, resumes):\n",
    "    \"\"\"\n",
    "    Search and rank resumes against a job description.\n",
    "    \n",
    "    Args:\n",
    "        job_description (str): Job description to match against resumes\n",
    "        resumes (dict): Dictionary of resume texts with filenames as keys\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Formatted output string and results DataFrame\n",
    "    \"\"\"\n",
    "    # Initialize models\n",
    "    models_dict = initialize_models()\n",
    "    \n",
    "    # Store results for each model\n",
    "    all_results = []\n",
    "    \n",
    "    try:\n",
    "        # Generate query embeddings for each model\n",
    "        query_embeddings = {}\n",
    "        for config in MODEL_CONFIGS:\n",
    "            model_name = config['name']\n",
    "            query_embeddings[model_name] = generate_embeddings(job_description, models_dict[model_name])\n",
    "        \n",
    "        # Process each resume\n",
    "        for file_name, text in resumes.items():\n",
    "            # Preprocess resume\n",
    "            preprocessed_resume = preprocess_resume(text)\n",
    "            \n",
    "            # Create a result dictionary for this resume\n",
    "            result = {\n",
    "                'file_name': file_name, \n",
    "                'resume_content': preprocessed_resume,\n",
    "                'job_description': job_description  # Add job description to each result\n",
    "            }\n",
    "            \n",
    "            # Calculate similarity for each model\n",
    "            for config in MODEL_CONFIGS:\n",
    "                model_name = config['name']\n",
    "                model_info = models_dict[model_name]\n",
    "                \n",
    "                # Generate resume embeddings with more sections\n",
    "                embedding_sections = [\n",
    "                    preprocessed_resume.get('work_experience', ''),\n",
    "                    preprocessed_resume.get('education', ''),\n",
    "                    preprocessed_resume.get('skills', ''),\n",
    "                    preprocessed_resume.get('summary', ''),\n",
    "                    preprocessed_resume.get('projects', ''),\n",
    "                    preprocessed_resume.get('certifications', ''),\n",
    "                ]\n",
    "                \n",
    "                # Combine embeddings\n",
    "                resume_embeddings = [\n",
    "                    generate_embeddings(section, model_info)\n",
    "                    for section in embedding_sections\n",
    "                    if section.strip()\n",
    "                ]\n",
    "                \n",
    "                # Average embeddings if any exist\n",
    "                if resume_embeddings:\n",
    "                    resume_embedding = np.mean(resume_embeddings, axis=0)\n",
    "                else:\n",
    "                    # Fallback if no embeddings generated\n",
    "                    resume_embedding = generate_embeddings('', model_info)\n",
    "                \n",
    "                # Calculate cosine similarity\n",
    "                similarity = cosine_similarity([query_embeddings[model_name]], [resume_embedding])[0][0]\n",
    "                \n",
    "                # Store model-specific similarity\n",
    "                result[f'{model_name}_similarity'] = similarity\n",
    "            \n",
    "            # Calculate weighted combined similarity\n",
    "            combined_similarity = sum(\n",
    "                result[f'{config[\"name\"]}_similarity'] * config['weight']\n",
    "                for config in MODEL_CONFIGS\n",
    "            )\n",
    "            \n",
    "            # Normalize to 0-1 range\n",
    "            result['combined_similarity'] = max(0, min(1, combined_similarity))\n",
    "            \n",
    "            # Append the result for the resume\n",
    "            all_results.append(result)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Sort the DataFrame by combined similarity\n",
    "        results_df = results_df.sort_values('combined_similarity', ascending=False)\n",
    "        \n",
    "        # Generate text output (without job description)\n",
    "        output = \"Search Results:\\n\\n\"\n",
    "        for _, result in results_df.iterrows():\n",
    "            output += f\"File: {result['file_name']}\\n\"\n",
    "            for config in MODEL_CONFIGS:\n",
    "                model_name = config['name']\n",
    "                output += f\"{model_name} Similarity: {result[f'{model_name}_similarity']:.4f}\\n\"\n",
    "            output += f\"Combined Similarity: {result['combined_similarity']:.4f}\\n\\n\"\n",
    "        \n",
    "        global search_results\n",
    "        search_results = results_df\n",
    "        return output, results_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error occurred: {e}\", None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_files(query, files):\n",
    "    # Convert uploaded files to resumes dictionary\n",
    "    resumes = {}\n",
    "    for file in files:\n",
    "        # Extract text from the file\n",
    "        text = extract_text_from_file(file.name)\n",
    "        resumes[os.path.basename(file.name)] = text\n",
    "    \n",
    "    # Call search_resumes with query and resumes\n",
    "    output, results_df = search_resumes(query, resumes)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import together\n",
    "import pandas as pd\n",
    "\n",
    "def generate_ideal_resume(job_description):\n",
    "    \"\"\"\n",
    "    Generate an ideal resume for a given job description using Together AI.\n",
    "    \n",
    "    Args:\n",
    "        job_description (str): Job description to base the ideal resume on\n",
    "    \n",
    "    Returns:\n",
    "        str: Ideal resume text\n",
    "    \"\"\"\n",
    "    client = together.Together(api_key=api_key)\n",
    "    \n",
    "    # Prompt to generate an ideal resume\n",
    "    prompt = f\"\"\"You are an expert resume writer. Create an ideal resume for the following job description:\n",
    "\n",
    "{job_description}\n",
    "\n",
    "Please create a comprehensive resume that highlights:\n",
    "- Relevant work experience\n",
    "- Key skills matching the job requirements\n",
    "- Professional summary\n",
    "- Notable achievements\n",
    "- Technical and soft skills\n",
    "\n",
    "Format the resume professionally, focusing on the most critical aspects for this role.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert resume writer creating an ideal resume.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        top_p=0.7,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1.0,\n",
    "        stop=[\"<|eot_id|>\",\"<|eom_id|>\"]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_resume(ideal_resume, candidate_resume, job_description, filename, similarities):\n",
    "    ideal_resume=preprocess_resume(ideal_resume)\n",
    "    \"\"\"\n",
    "    Evaluate a candidate's resume against an ideal resume using Together AI.\n",
    "    \n",
    "    Args:\n",
    "        ideal_resume (str): Ideal resume text\n",
    "        candidate_resume (str): Candidate's resume text\n",
    "        job_description (str): Job description\n",
    "        filename (str): Name of the resume file\n",
    "        similarities (dict): Semantic similarities for different models\n",
    "    \n",
    "    Returns:\n",
    "        str: Evaluation summary\n",
    "    \"\"\"\n",
    "    client = together.Together(api_key=api_key)\n",
    "    \n",
    "    # Prepare similarity information\n",
    "    similarity_info = \"\\n\".join([\n",
    "        f\"{model}: {similarity:.4f}\" \n",
    "        for model, similarity in similarities.items()\n",
    "    ])\n",
    "    \n",
    "    # Prompt for resume evaluation\n",
    "    prompt = f\"\"\"You are an expert HR recruiter. Compare the following resumes:\n",
    "\n",
    "Job Description:\n",
    "{job_description}\n",
    "\n",
    "Semantic Similarities:\n",
    "{similarity_info}\n",
    "\n",
    "Ideal Resume:\n",
    "{ideal_resume}\n",
    "\n",
    "Candidate Resume:\n",
    "{candidate_resume}\n",
    "\n",
    "Provide a detailed evaluation following this format:\n",
    "Name: {filename}\n",
    "Score out of 10: [Numerical score based on job fit AND semantic similarities]\n",
    "Summary: [Concise overview of candidate's strengths and weaknesses]\n",
    "AI Suggestion: [Hire/Do Not Hire recommendation with specific reasoning]\n",
    "\n",
    "Consider the provided semantic similarities as an additional factor in your evaluation. \n",
    "Focus primarily on experience and skills. Be objective and provide constructive insights.\n",
    "Consider these weights\n",
    "\"work_experience\": 0.5, \"skills\": 0.3, \"education\": 0.2, \"summary\": 0.1, \"projects\": 0.2, \"certifications\": 0.1\n",
    "Do not care about formatting\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert HR recruiter evaluating resumes.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.7,\n",
    "        top_p=0.7,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1.0,\n",
    "        stop=[\"<|eot_id|>\",\"<|eom_id|>\"]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def llm_processor(search_results):\n",
    "    \"\"\"\n",
    "    Process and evaluate resumes from the search results.\n",
    "    \n",
    "    Args:\n",
    "        search_results (pd.DataFrame): DataFrame with resume search results\n",
    "    \n",
    "    Returns:\n",
    "        list: Evaluation summaries for each candidate\n",
    "    \"\"\"\n",
    "    # Extract job description (assuming it's the same for all rows)\n",
    "    job_description = search_results['job_description'].iloc[0]\n",
    "    \n",
    "    # Generate ideal resume\n",
    "    ideal_resume = generate_ideal_resume(job_description)\n",
    "    print(\"Ideal Resume Generated:\")\n",
    "    print(ideal_resume)\n",
    "    print(\"\\n--- Resume Evaluations ---\\n\")\n",
    "    \n",
    "    # Store evaluations\n",
    "    evaluations = []\n",
    "    \n",
    "    # Evaluate each candidate resume\n",
    "    for _, row in search_results.iterrows():\n",
    "        # Extract resume content and similarities\n",
    "        candidate_resume = str(row['resume_content'])\n",
    "        filename = row['file_name']\n",
    "        # Collect similarities\n",
    "        similarities = {\n",
    "            'bert-base-uncased': row['bert-base-uncased_similarity'],\n",
    "            'roberta-base': row['roberta-base_similarity'],\n",
    "            #'albert-base-v2': row['albert-base-v2_similarity'],\n",
    "            'combined': row['combined_similarity']\n",
    "        }\n",
    "        \n",
    "        # Evaluate resume\n",
    "        evaluation = evaluate_resume(\n",
    "            ideal_resume, \n",
    "            candidate_resume, \n",
    "            job_description, \n",
    "            filename, \n",
    "            similarities\n",
    "        )\n",
    "        #print(evaluation)\n",
    "        print(\"\\n--------------------------\\n\")\n",
    "        \n",
    "        evaluations.append(evaluation)\n",
    "        print(candidate_resume)\n",
    "    \n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from g4f.client import Client\n",
    "\n",
    "# Function to evaluate LLaMA's output using GPT-4\n",
    "def evaluate_llama_output_with_gpt4(llama_evaluation, candidate_resume, job_description, filename):\n",
    "    \"\"\"\n",
    "    Evaluate LLaMA's evaluation output using GPT-4 (via g4f.client).\n",
    "    \"\"\"\n",
    "    # Prepare the prompt for GPT-4\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert HR recruiter. Here is an evaluation of a candidate's resume generated by LLaMA:\n",
    "\n",
    "    LLaMA Evaluation:\n",
    "    {llama_evaluation}\n",
    "\n",
    "    Job Description:\n",
    "    {job_description}\n",
    "\n",
    "    Candidate Resume:\n",
    "    {candidate_resume}\n",
    "\n",
    "    Please provide a critical analysis of the LLaMA evaluation.\n",
    "    Focus on the accuracy, thoroughness, and relevance of LLaMA's output.\n",
    "    Suggest areas of improvement and give a final recommendation (e.g., hire/do not hire)\n",
    "    Do not care about formatting.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a client instance to interact with GPT-4\n",
    "    client = Client()\n",
    "\n",
    "    # Call GPT-4 via the g4f.client API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # Replace with the correct model identifier\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "        top_p=0.7,\n",
    "        frequency_penalty=0.5,\n",
    "        presence_penalty=0.5\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Updated Process Function\n",
    "def process_resume(job_description, resume_file):\n",
    "    # Process the resumes\n",
    "    output = process_files(job_description, resume_file)\n",
    "    \n",
    "    # Get evaluations from the LLM processor\n",
    "    evaluations = llm_processor(search_results)\n",
    "    \n",
    "    # Generate GPT-4 evaluations for each resume\n",
    "    gpt4_evaluations = []\n",
    "    for _, row in search_results.iterrows():\n",
    "        llama_evaluation = f\"\"\"\n",
    "        BERT Similarity: {row['bert-base-uncased_similarity']:.4f}\n",
    "        RoBERTa Similarity: {row['roberta-base_similarity']:.4f}\n",
    "        Combined Similarity: {row['combined_similarity']:.4f}\n",
    "        \"\"\"\n",
    "        candidate_resume = row['resume_content']\n",
    "        filename = row['file_name']\n",
    "        \n",
    "        # Call GPT-4 evaluation\n",
    "        gpt4_evaluation = evaluate_llama_output_with_gpt4(\n",
    "            llama_evaluation, \n",
    "            candidate_resume, \n",
    "            job_description, \n",
    "            filename\n",
    "        )\n",
    "        gpt4_evaluations.append(f\"File: {filename}\\n{gpt4_evaluation}\")\n",
    "    \n",
    "    # Join the GPT-4 evaluations with two line breaks\n",
    "    formatted_gpt4_output = \"\\n\\n\".join(gpt4_evaluations)\n",
    "    \n",
    "    # Clean up the LLM Processor Output to format text properly (replacing \\n with actual line breaks)\n",
    "    evaluations=  \" \\n\\n\".join(evaluations)\n",
    "    \n",
    "    return output, evaluations, formatted_gpt4_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with gr.Blocks() as demo:\n",
    "    # Add a title to the interface\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        ## Resume Evaluation Tool âœ…\n",
    "        Upload resumes and provide a job description to get similarity evaluations and detailed feedback. ðŸ“„\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            job_description_input = gr.Textbox(label=\"Job Description\")\n",
    "            resume_file_input = gr.File(\n",
    "                file_types=[\".pdf\", \".doc\", \".docx\", \".txt\"],\n",
    "                file_count=\"multiple\",\n",
    "                label=\"Upload Resumes\",\n",
    "                interactive=True\n",
    "            )\n",
    "            process_files_output = gr.Textbox(label=\"Process Files Output\", lines=10)\n",
    "        with gr.Column():\n",
    "            llm_output = gr.Textbox(label=\"LLM Processor Output\", lines=10)\n",
    "            gpt4_output = gr.Textbox(label=\"GPT-4 Evaluation Output\", lines=10)\n",
    "   \n",
    "    process_button = gr.Button(\"Process\")\n",
    "    process_button.click(\n",
    "        fn=process_resume,\n",
    "        inputs=[job_description_input, resume_file_input],\n",
    "        outputs=[process_files_output, llm_output, gpt4_output]\n",
    "    )\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
